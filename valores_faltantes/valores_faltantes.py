# -*- coding: utf-8 -*-
"""valores_faltantes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18Bl3l2n5avTcfBlnsOMXZM56Nkd7lIN5

Testamos diversos modelos e selecionamos aquele que tinha o menor erro. O que mais podemos fazer?

Vamos carregar os nossos arquivos novamente.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn.metrics import mean_absolute_error
from sklearn.ensemble import RandomForestRegressor

dados_treino = pd.read_csv('treino.csv', index_col='Id')
dados_teste = pd.read_csv('teste.csv', index_col='Id')

"""Legal, agora podemos inspecioná-los melhor."""

dados_treino.head(10)

"""Repare no conteúdo da coluna Alley. O que são esses NaN? NaN significa not a number e nesse caso, de que não temos um valor nessa coluna, o que não ajuda o nosso modelo, uma vez que ele se baseia em dados. 

Quantos NaN será que temos nessa coluna? Para responder essa pergunta, primeiro vemos quais deles são nulos com isnull().
"""

dados_treino.Alley.isnull()

"""Repare que isso volta um booleano para a gente e agora fazemos a soma desses valores com sum()."""

dados_treino.Alley.isnull().sum()

"""E olhe só, de 1460 entradas, 1369 não tem valores. O que será que podemos fazer quanto a isso? Tem alguns métodos, uma saída é simplesmente jogar essa coluna fora. Para fazer isso usaríamos .drop(). Primeiro vou fazer uma cópia dos dados."""

dados_treino_copiado = dados_treino.copy()

"""Passamos o axis=1 para o drop para indicar que é uma coluna."""

dados_treino_copiado.drop('Alley', axis=1)

"""Repare que não temos mais a nossa coluna, mas será que essa foi uma boa idéia, pois tinhamos outros valores lá que foram embora uma vez que jogamos toda a coluna fora, então uma outra abordagem seria, por exemplo, colocar outros valores nessa coluna no lugar dos NaN. Mas precisamos de valores que não tendenciariam os nossos dados, por exemplo, substituir pela media. Mas como vamos substituir pela média se o conteúdos dessas colunas são palavras?

Vamos dar um passo de cada vez. Primeiro vamos pegar apenas dados numéricos e entender como podemos fazer com eles, feito isso, vamos pegar dados em texto e ver o que podemos fazer com eles.

Como pegamos apenas os numéricos? Tudo o que é palavra é object, basta excluírmos os object e ver o que sobra para a gente. Faremos isso usando o exclude do select_dtypes()
"""

dados_treino_copiado.select_dtypes(exclude=['object'])

"""Veja que agora ficamos com 37 colunas, antes tinhamos 80. 

Repare também que o SalePrice, a coluna que queremos advinhar esta no nosso X, e como querêmos prevê-la, isso não é uma boa idéia, ou seja, vamos ter que tirá-la do X também. Mas antes vamos ver se ela tem valores faltantes e atribui-la a y.

Para fazer isso, usamos o dropna, e se tiver uma linha que vai ser o axis 0 aqui que tenha Nas no SalePrice, dropamos essa linha.
"""

dados_treino_copiado.dropna(axis=0, subset=['SalePrice'], inplace=True)

"""Agora nosso y está pronto para receber os dados de SalePrice."""

y = dados_treino_copiado.SalePrice

"""Agora que já passamos o SalePrice para o y, podemos excluir a coluna (axis=1) dos dados de treino."""

dados_treino_copiado.drop(['SalePrice'], axis=1, inplace=True)

"""Temos o nosso y, mas e o nosso X? Vamos fazer a atribuição e ver se está tudo certo."""

X = dados_treino_copiado

X.info()

"""Repare que SalePrice não está mais no nosso X, no entanto, ele está cheio de objects, porque? Porque não fizemos in place que nem os outros métodos e não atribuimos a X, então vamos tirar os object novamente e atribuir o resultado a X."""

X = dados_treino_copiado.select_dtypes(exclude=['object'])

X.info()

"""Beleza, agora temos 36 colunas de inteiros e alguns floats no nosso X, e o nosso X_teste? O que fazemos com eles? 

Por enquanto não vamos alterar os valores do nosso X_teste, mas podemos ter X com 36 colunas e X_teste com 80? 

Não, certo, então para ficar justo vamos também testar nosso modelo apenas com valores numéricos.
"""

X_teste = dados_teste.copy().select_dtypes(exclude=['object'])

X_teste.info()

"""O que fizemos até agora? 

Nós tiramos valores faltantes das linhas do SalePrice, removemos o SalePrice de X, fizemos a atribuição do SalePrice a y, também definimos X e X_teste para ter apenas valores numéricos.

Isso resolve o nosso problema inicial de valores faltantes no dataset?

Não, vamos ver isso jajá, o que fizemos até agora foi pré processar os nossos dados de entrada.

Agora que isso está feito, vamos dividir esses dados para colocá-los no nosso modelo.
"""

X_treino, X_valid, y_treino, y_valid = train_test_split(X, y,
                                                        train_size=0.8,
                                                        test_size=0.2,
                                                        random_state=42)

"""Beleza, agora podemos começar a mexer nos nossos dados como queríamos fazer no começo. Primeiro vamos entender quantas colunas e linhas temos nos dados de treino. Fazemos isso com .shape."""

X_treino.shape

"""Repare que o shape nos devolve que são 1168 linhas e 36 colunas, e quais dessas colunas tem valores nulos?

Já sabemos como ver isso usando is null e sum.
"""

colunas_com_valores_faltantes = X_treino.isnull().sum()

colunas_com_valores_faltantes

"""Repare que isso devolve para a gente as colunas com valores faltantes, a quantidade desses valores e também as que tem 0, eu quero ver apenas aquelas que tem valores faltantes.

Para fazer isso, podemos passar uma condição para o dataframe para que ele liste os valores maiores que 0.
"""

colunas_com_valores_faltantes[colunas_com_valores_faltantes > 0]

"""Já sabemos que temos colunas com valores faltantes. Agora precisamos escolher o que vamos fazer com elas, será que temos um número muito grande de valores faltantes?

Se temos 1168 entradas, e os valores faltantes são:
"""

(217 + 6 + 64)/1168

"""Veja que 24 a 25% dos nossos dados estão faltando, isso não é tão significativo, podemos tentar uma primeira abordagem dropando esses valores e vendo que resultado isso tem no nosso modelo.

Primeiro, vamos pegar o nome das colunas com valores faltantes.
"""

colunas_com_valores_faltantes = [coluna for coluna in X_treino.columns if X_treino[coluna].isnull().any()]

"""O que estamos fazendo aqui é determinando que para cada coluna nas colunas de treino, se ela tiver qualquer (any) valor nulo, guardamos o nome dela na lista."""

colunas_com_valores_faltantes

"""Beleza, agora que temos o nome das nossas colunas, podemos dropa-las do treino e da validação."""

X_treino_reduzido = X_treino.drop(colunas_com_valores_faltantes, axis=1)
X_valid_reduzido = X_valid.drop(colunas_com_valores_faltantes, axis=1)

"""Agora que limpamos os dados do nosso modelo de valores faltantes, podemos criar o modelo, ajustar, predizer e calcular o erro para ver que resultado isso teve."""

modelo = RandomForestRegressor(n_estimators=50, random_state=42)
modelo.fit(X_treino_reduzido, y_treino)
preds = modelo.predict(X_valid_reduzido)
mae = mean_absolute_error(y_valid, preds)

mae

"""Legal, parece que que o nosso erro baixou bastante.

Usamos a abordagem de dropar as colunas, e se a gente mexesse nos valores como tinhamos falado? Será que é menor ou pior?

Fazer isso é chamado de imputação, estamos imputando valores, vamos usar algo que chama Simple Imputer do sklearn.
"""

from sklearn.impute import SimpleImputer

imputador_simples = SimpleImputer()

"""Com o imputador criado, agora vamos fazer algo que é parecido com o que fazemos com o modelo para os nossos dados. Vamos ajustar e transforma-los."""

X_treino_imputado = pd.DataFrame(imputador_simples.fit_transform(X_treino))

X_treino.head(5)

X_treino_imputado.head(5)

"""Repare que agora onde antes tinhamos valores faltantes agora temos uns números. Esses números são a média do valor de cada coluna, como? 

Porque apenas criamos o Simple imputer e o default dele é preencher com a média.

Repare também que perdemos a informação do nome das colunas, então vamos voltar isso.
"""

X_treino_imputado.columns = X_treino.columns

X_treino_imputado.head(5)

"""Agora vamos fazer o mesmo para X_valid com a diferença de que não faremos o fit, apenas o transform. Do mesmo modo que fazemos com o nosso modelo, não queremos que o imputador aprenda o nosso padrão de avaliação."""

X_valid.head(5)

X_valid_imputado = pd.DataFrame(imputador_simples.transform(X_valid))

X_valid_imputado.head(5)

"""Voltando as colunas."""

X_valid_imputado.columns = X_valid.columns

"""Agora podemos novamente fazer o fit, predict e calcular o erro."""

modelo_imputacao = RandomForestRegressor(n_estimators=50, random_state=42)
modelo_imputacao.fit(X_treino_imputado, y_treino)
preds_imputado = modelo_imputacao.predict(X_valid_imputado)
mae_imputado = mean_absolute_error(y_valid, preds_imputado)

mae_imputado

mae

"""Repare que se compararmos o mae imputado com o mae anterior, este era menor. Porque será?

Veja que ao excluirmos as colunas, perdemos bastante informação, o que diminui a complexidade do que o nosso modelo está processando e é isso que faz o erro ficar menor.

Além disso, repare que estamos usando a média dos valores do dataset para fazermos a imputação, será que essa é a melhor abordagem?

Temos alguns valores aqui numa coluna como 

60, 7, 3, 5, 1, NaN

A média desses valores seria 15, então ficaríamos com 

60, 7, 3, 5, 1, 15 

será que não estamos tendenciando um pouco os nossos dados? Repare que quando fazemos a média, estamos considerando tanto o valor 60 quanto o valor 1, e o 60 vai pesar mais.

O que poderíamos fazer então? Podemos usar algo que tendencie menos. Se ordenarmos os nossos números, temos:

1, 3, 5, 7, 60 e NaN

Pegando o do meio, ficaríamos com 5, essa é a mediana dos nossos dados e aí teríamos

1, 3, 5, 7, 60, 5

Parece uma idéia melhor do que a média, vamos ver qual o resultado disso para o nosso conjunto de dados.

Vamos repetir o mesmo processo de imputação, agora com um novo imputador cuja estratégia é usar a mediana.
"""

imputador_mediana = SimpleImputer(strategy='median')

X_treino_mediana = pd.DataFrame(imputador_mediana.fit_transform(X_treino))
X_valid_mediana = pd.DataFrame(imputador_mediana.transform(X_valid))

X_treino_mediana.columns = X_treino.columns
X_valid_mediana.columns = X_valid.columns

modelo_mediana = RandomForestRegressor(n_estimators=50, random_state=42)
modelo_mediana.fit(X_treino_mediana, y_treino)

preds_mediana = modelo_mediana.predict(X_valid_mediana)
mae_mediana = mean_absolute_error(y_valid, preds_mediana)

print('MAE do modelo %s: %d' % ('com valores dropados', mae))
print('MAE do modelo %s: %d' % ('imputado com média', mae_imputado))
print('MAE do modelo %s: %d' % ('imputado com mediana', mae_mediana))

"""Como o erro da mediana está apenas um pouco maior que o da média e é uma abordagem que considera mais informações e tendencia menos os dados, vou escolher esse último modelo.

Agora vamos fazer as predições finais com os dados de teste.
"""

preds_teste = modelo_mediana.predict(X_teste)

"""Repare que tivemos um erro aqui, porque? 

Lembra que deixamos o nosso X teste com colunas numéricas mas que não mexemos nos valores dele? 

Agora como ele contém NaN não conseguimos prever. Então precisamos também fazer a imputação da mediana para o X teste.
"""

X_teste_mediana = pd.DataFrame(imputador_mediana.transform(X_teste))

"""Agora podemos fazer a predição e salvar mais um csv com os resultados."""

preds_teste = modelo_mediana.predict(X_teste_mediana)

resultados_imputacao = {'Id': X_teste.index, 'SalePrice': preds_teste}

resultados = pd.DataFrame(resultados_imputacao)

resultados.to_csv('resultados_imputacao.csv', index=False)